import streamlit as st
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents.base import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain_core.runnables import Runnable
from langchain.schema.output_parser import StrOutputParser
from langchain_community.document_loaders import PyMuPDFLoader

from typing import List
import os
import re
import csv
import openai
#from streamlit.runtime.uploaded_file_manager import UploadedFile
import fitz  # PyMuPDF


### í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ: íŒŒì¼ì— ì €ì¥ëœ ë³€ìˆ˜ë“¤ì„ í™˜ê²½ ë³€ìˆ˜ë¡œ ë¡œë“œ
load_dotenv()

# API í‚¤ ê°€ì ¸ì˜¤ê¸°
OPENAI_API_KEY = os.getenv("API_KEY")
openai.api_key = OPENAI_API_KEY

print(OPENAI_API_KEY)


### PDF Embeddings

# 1: ì €ì¥ëœ PDF íŒŒì¼ì„ Documentë¡œ ë³€í™˜
def pdf_to_documents(pdf_path: str) -> List[Document]:
    loader = PyMuPDFLoader(pdf_path)
    documents = loader.load()
    for d in documents:
        d.metadata['file_path'] = pdf_path
    return documents

# 2: Documentë¥¼ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• 
def chunk_documents(documents: List[Document]) -> List[Document]:
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    return text_splitter.split_documents(documents)

# 3: Documentë¥¼ ë²¡í„° DBì— ì €ì¥
def save_to_vector_store(documents: List[Document]) -> None:
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vector_store = FAISS.from_documents(documents, embedding=embeddings)
    vector_store.save_local("faiss_index")


### RAG

# RAG template ì •ì˜
def get_rag_chain() -> Runnable:
    template = """
    ì•„ë˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:
    - ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µì€ 5ì¤„ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    - ì• ë§¤í•˜ê±°ë‚˜ ëª¨ë¥´ëŠ” ë‚´ìš©ì€ "ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.
    - ê³µì†í•œ í‘œí˜„ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.

    ì»¨í…ìŠ¤íŠ¸: {context}

    ì§ˆë¬¸: {question}

    ì‘ë‹µ:"""

    custom_rag_prompt = PromptTemplate.from_template(template)
    model = ChatOpenAI(model="gpt-4o")

    return custom_rag_prompt | model | StrOutputParser()
    # í…œí”Œë¦¿ì„ í†µí•´ í”„ë¡¬í”„íŠ¸ê°€ ì™„ì„± -> ëª¨ë¸ ì…ë ¥ê°’ -> ì¶œë ¥ê°’ì„ ë¬¸ìì—´ë¡œ ë‚˜íƒ€ëƒ„


# ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ RAG ì²˜ë¦¬
# @st.cache_data # ë°ì´í„° ì²˜ë¦¬ ê²°ê³¼ë¥¼ ìºì‹±í•˜ì—¬ ë°ì´í„° ë¡œë“œë‚˜ ê³„ì‚° ì‘ì—…ì„ ë¹ ë¥´ê²Œ ìˆ˜í–‰
@st.cache_resource # ë¹„ìš©ì´ í° ë¦¬ì†ŒìŠ¤ í•œ ë²ˆë§Œ ìƒì„±í•˜ê³  ì¬ì‚¬ìš©

def process_question(user_question):
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    
    # ë²¡í„° DB í˜¸ì¶œ
    new_db = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)

    # ê´€ë ¨ ë¬¸ì„œ 3ê°œë¥¼ í˜¸ì¶œí•˜ëŠ” Retriever ìƒì„±
    retriever = new_db.as_retriever(search_kwargs={"k": 3})

    # ì‚¬ìš©ì ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ 3ê°œ ê²€ìƒ‰
    retrieve_docs: List[Document] = retriever.invoke(user_question)

    # RAG ì²´ì¸ ì„ ì–¸
    chain = get_rag_chain()

    # ì§ˆë¬¸ê³¼ ë¬¸ë§¥ì„ ë„£ì–´ì„œ ì²´ì¸ ê²°ê³¼ í˜¸ì¶œ
    response = chain.invoke({"question": user_question, "context": retrieve_docs})

    return response, retrieve_docs


def create_buttons(options):
    for option in options:
        if st.button(option[0] if isinstance(option, tuple) else option):
            st.session_state.selected_category = option[1] if isinstance(option, tuple) else option


### ì±—ë´‡

# íŒŒì¼ëª… ìì—° ì •ë ¬ í‚¤ ìƒì„± í•¨ìˆ˜
def natural_sort_key(s):
    return [int(text) if text.isdigit() else text for text in re.split(r'(\d+)', s)]

def main():
    st.set_page_config(
        initial_sidebar_state="expanded",
        layout="wide",
        page_icon="ğŸ¤–",
        page_title="ë””ì§€í„¸ê²½ì˜ì „ê³µ ì±—ë´‡")

    st.header("ë””ì§€í„¸ê²½ì˜ì „ê³µ ì±—ë´‡")
    st.text("ì§ˆë¬¸í•˜ê³ ì‹¶ì€ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”")

    left1_column, left2_column, mid_column, right_column = st.columns([0.3, 0.3, 1, 0.85])
    with left1_column:
        st.text("ë””ì§€í„¸ê²½ì˜í•™ê³¼")

        if 'selected_category' not in st.session_state:
            st.session_state.selected_category = None

        categories = [
            "í•™ê³¼ ì •ë³´", "ì „ê³µ ê³¼ëª©", "êµë‚´ ì¥í•™ê¸ˆ", "í•™êµ í–‰ì‚¬",
            "ì†Œëª¨ì„", "ë¹„êµê³¼", "êµí™˜ í•™ìƒ"]

        create_buttons(categories)

    with left2_column:
        st.text("í•™ë…„ë³„")

        # í•™ë…„ë³„ ë²„íŠ¼ ìƒì„±
        grade_levels = [
        ("20í•™ë²ˆ ì´ì „", "20ì´ì „"), ("21í•™ë²ˆ", "21"),
        ("22í•™ë²ˆ", "22"), ("23í•™ë²ˆ", "23"), ("24í•™ë²ˆ", "24")]

        for grade, code in grade_levels:
            if st.button(grade):
                st.session_state.selected_grade = code
                st.session_state.selected_category = f"{code}"

        if st.session_state.selected_category:
            pdf_path = f"document/{st.session_state.selected_category}.pdf" # ì½”ë“œ ìˆ˜ì •ì •: document/
            pdf_document = pdf_to_documents(pdf_path)
            smaller_documents = chunk_documents(pdf_document)
            save_to_vector_store(smaller_documents)


    with mid_column:
        if "messages" not in st.session_state:
            st.session_state.messages = []

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("ì„ íƒí•˜ì‹  ì¹´í…Œê³ ë¦¬ì—ì„œ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."):
            with st.chat_message("user"):
                st.markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})

            # ì§ˆë¬¸ ì²˜ë¦¬
            try:
                response, context = process_question(prompt)
                with st.chat_message("assistant"):
                    st.markdown(response)
                    with st.expander("ê´€ë ¨ ë¬¸ì„œ ë³´ê¸°"):
                        for document in context:
                            st.write(document.page_content)
            except Exception as e:
                st.error(f"ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    with right_column:
        #if prompt:
            #response, context = process_question(prompt)
            #for document in context:
                #with st.expander("ê´€ë ¨ ë¬¸ì„œ"):
                    #st.write(document.page_content)

        if 'user_questions' not in st.session_state:
            st.session_state.user_questions = []
        if 'user_feedback' not in st.session_state:
            st.session_state.user_feedback = []


        # ì§ˆë¬¸ ì…ë ¥
        user_question = st.text_input(
            "ì±—ë´‡ì„ í†µí•´ ì •ë³´ë¥¼ ì–»ì§€ ëª»í•˜ì˜€ê±°ë‚˜ ì¶”ê°€ì ìœ¼ë¡œ ê¶ê¸ˆí•œ ì§ˆë¬¸ì„ ë‚¨ê²¨ì£¼ì„¸ìš”!",
            placeholder="ê³¼ëª© ë³€ê²½ or í–‰ì‚¬ ë¬¸ì˜"
        )

        if st.button("ì§ˆë¬¸ ì œì¶œ"):
            if user_question:
                # ì„¸ì…˜ ìƒíƒœì— ì§ˆë¬¸ ì €ì¥
                if "user_questions" not in st.session_state:
                    st.session_state.user_questions = []
                st.session_state.user_questions.append({"ì§ˆë¬¸": user_question})
                st.success("ì§ˆë¬¸ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ì‘ë‹µ í”¼ë“œë°±
        st.text("")
        feedback = st.radio("ì‘ë‹µì´ ë§Œì¡±ìŠ¤ëŸ¬ìš°ì…¨ë‚˜ìš”?", ("ë§Œì¡±", "ë¶ˆë§Œì¡±"))

        if feedback == "ë§Œì¡±":
            st.success("ê°ì‚¬í•©ë‹ˆë‹¤! ë„ì›€ì´ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤.")
        elif feedback == "ë¶ˆë§Œì¡±":
            st.warning("ë¶ˆë§Œì¡±í•˜ì‹  ë¶€ë¶„ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê² ìŠµë‹ˆë‹¤.")

            # ë¶ˆë§Œì¡± ì‚¬ìœ  ì…ë ¥
            reason = st.text_area("ë¶ˆë§Œì¡±í•œ ë¶€ë¶„ì´ ë¬´ì—‡ì¸ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.")

            if st.button("í”¼ë“œë°± ì œì¶œ"):
                if reason:
                    # ì„¸ì…˜ ìƒíƒœì— í”¼ë“œë°± ì €ì¥
                    if "user_feedback" not in st.session_state:
                        st.session_state.user_feedback = []
                    st.session_state.user_feedback.append({"í”¼ë“œë°±": reason})
                    st.success("í”¼ë“œë°±ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ë¶ˆë§Œì¡± ì‚¬ìœ ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

        # ì§ˆë¬¸ ë° í”¼ë“œë°± CSV ì €ì¥
        if st.button("ì§ˆë¬¸ ë° í”¼ë“œë°± ë“±ë¡í•˜ê¸°"):
            # ì§ˆë¬¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            user_question = st.session_state.user_questions if "user_questions" in st.session_state else []
            reason = st.session_state.user_feedback if "user_feedback" in st.session_state else []

            # ì§ˆë¬¸ê³¼ í”¼ë“œë°±ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë³‘í•©
            max_length = max(len(user_question), len(reason))
            user_question = user_question + [""] * (max_length - len(user_question))  # ì§§ì€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¹ˆ ë¬¸ìì—´ë¡œ ì±„ì›€
            reason = reason + [""] * (max_length - len(reason))  # ì§§ì€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¹ˆ ë¬¸ìì—´ë¡œ ì±„ì›€

            # CSV íŒŒì¼ ì‘ì„±
            if user_question or reason:
                try:
                    with open("questions_and_feedback.csv", mode="w", encoding="utf-8-sig", newline="") as file:
                        writer = csv.writer(file)
                        # í—¤ë” ì‘ì„±
                        writer.writerow(["ì§ˆë¬¸", "í”¼ë“œë°±"])
                        # ì§ˆë¬¸ê³¼ í”¼ë“œë°± ë°ì´í„° ì‘ì„±
                        for q, f in zip(user_question, reason):
                            writer.writerow([q, f])
                    st.success("ì§ˆë¬¸ê³¼ í”¼ë“œë°±ì´ ë“±ë¡ ë˜ì—ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
            else:
                st.warning("ì €ì¥í•  ì§ˆë¬¸ ë˜ëŠ” í”¼ë“œë°± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.text("")
        st.text("")
        st.text("ê³ ë ¤ëŒ€í•™êµ ì„¸ì¢…ìº í¼ìŠ¤ ë””ì§€í„¸ê²½ì˜ì „ê³µ í™ˆí˜ì´ì§€ë¥¼ ì°¸ê³ í•˜ê±°ë‚˜ \n ë””ì§€í„¸ê²½ì˜ì „ê³µ ì‚¬ë¬´ì‹¤'(044-860-1560)'ì— ì „í™”í•˜ì—¬ ë¬¸ì˜ì‚¬í•­ì„ \n ì ‘ìˆ˜í•˜ì„¸ìš”.")



if __name__ == "__main__":
    main()

# start : streamlit run "c:/Users/eunseok/OneDrive/ë°”íƒ• í™”ë©´/2024ë…„ 2í•™ê¸° ëŒ€ë‚´ì™¸ í™œë™/CURT/LangChain_RAG.py"
# stop : ctrl + c